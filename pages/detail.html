<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' width='16' height='16'><text x='0' y='12' font-size='12'>ğŸ“‹</text></svg>">
    <title>Content details</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../CSS/style.css"> <!-- å¼•å…¥å¤–éƒ¨CSS -->
    <link href="https://cdn.jsdelivr.net/npm/prismjs@1.24.0/themes/prism.css" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.24.0/prism.js"></script>
</head>
<body>
    <!-- ä¾§è¾¹æ  -->
    <div class="sidebar">
        <img src="../imgs/KDD26-Logo4-black.png" alt="Logo">
        <a href="../index.html">â­ Introduction</a>
        <a href="detail.html" class="active">ğŸ“‹ Topic</a>
        <!-- <a href="timeline.html">ğŸ“… Time arrangement</a> -->
        <a href="call.html">ğŸ–Šï¸ Call for papers</a>
        <a href="organizers.html">ğŸ§‘â€ğŸ¤â€ğŸ§‘ Organizers & PC</a>
        <a href="talk.html">ğŸ”— Talk Details & Schedule</a>
    </div>

    <!-- å†…å®¹éƒ¨åˆ† -->
    <div class="content">
        <div class="container">
            <!-- é¡¶éƒ¨æ ‡é¢˜ -->
            <div class="header">
                <h1>ğŸ“‹ Topic</h1>
            </div>

            <!-- ä»»åŠ¡å†…å®¹ -->
            <div class="section">
                <h3>Topics of Interest: </h3>
                <p style="text-indent: 1em;">The workshop focuses on <b>advancing GML in the context of large models</b>. It explores how structured relational data and graph representations can enhance reasoning, generalization, and interpretability in modern AI systems. The workshop emphasizes how large models, especially LLMs, can assist GML, such as improving node classification, link prediction, and graph generation in low-resource or few-shot scenarios. We welcome work on using prompt tuning, instruction tuning, and in-context learning for graph tasks, as well as LLM-assisted data augmentation. We also explore hybrid methods that integrate graph data with foundation models, such as using knowledge graphs to guide representation learning.</p>
                <p style="text-indent: 1em;">We invite contributions that address theoretical foundations and practical applications of GML in the large model era. Topics include graph-structured explanations, graph structure alignment with LLM latent representations, and new paradigms for learning on complex graphs with LLMs. Application areas of interest include scientific discovery, knowledge graph completion, recommendation, and graph-based question answering, as well as new benchmarks and tools for evaluating LLM-augmented graph learning.</p>
            </div>
            <div class="section">
                <h3>Past Edition:</h3>
                <p style="text-indent: 1em;">The <b>â€œFrontiers in Graph Machine Learning for the Large Model Eraâ€</b> workshop: <a href="https://magic-group-buaa.github.io/CIKM2025_workshop/index.html" target="_blank">Link</a></p>
            </div>
    </div>
</body>
</html>